{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abeb981",
   "metadata": {},
   "source": [
    "# VQAScore Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710587f0",
   "metadata": {},
   "source": [
    " Code setup and VQAScore adopted from [here](https://github.com/linzhiqiu/t2v_metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80a580",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ba1b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/lucawilliams/miniforge3/envs/t2v\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.10\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              conda-forge/osx-arm64::bzip2-1.0.8-hd037594_8 \n",
      "  ca-certificates    conda-forge/noarch::ca-certificates-2025.10.5-hbd8a1cb_0 \n",
      "  icu                conda-forge/osx-arm64::icu-75.1-hfee45f7_0 \n",
      "  libexpat           conda-forge/osx-arm64::libexpat-2.7.1-hec049ff_0 \n",
      "  libffi             conda-forge/osx-arm64::libffi-3.5.2-he5f378a_0 \n",
      "  liblzma            conda-forge/osx-arm64::liblzma-5.8.1-h39f12f2_2 \n",
      "  libsqlite          conda-forge/osx-arm64::libsqlite-3.51.0-h8adb53f_0 \n",
      "  libzlib            conda-forge/osx-arm64::libzlib-1.3.1-h8359307_2 \n",
      "  ncurses            conda-forge/osx-arm64::ncurses-6.5-h5e97a16_3 \n",
      "  openssl            conda-forge/osx-arm64::openssl-3.6.0-h5503f6c_0 \n",
      "  pip                conda-forge/noarch::pip-25.3-pyh8b19718_0 \n",
      "  python             conda-forge/osx-arm64::python-3.10.19-hcd7f573_2_cpython \n",
      "  readline           conda-forge/osx-arm64::readline-8.2-h1d1bf99_2 \n",
      "  setuptools         conda-forge/noarch::setuptools-80.9.0-pyhff2d567_0 \n",
      "  tk                 conda-forge/osx-arm64::tk-8.6.13-h892fb3f_2 \n",
      "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
      "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate t2v\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Channels:\n",
      " - conda-forge\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - conda-forge\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/lucawilliams/miniforge3/envs/t2v\n",
      "\n",
      "  added / updated specs:\n",
      "    - ffmpeg\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aom                conda-forge/osx-arm64::aom-3.9.1-h7bae524_0 \n",
      "  cairo              conda-forge/osx-arm64::cairo-1.18.4-h6a3b0d2_0 \n",
      "  dav1d              conda-forge/osx-arm64::dav1d-1.2.1-hb547adb_0 \n",
      "  dbus               conda-forge/osx-arm64::dbus-1.16.2-hda038a8_0 \n",
      "  ffmpeg             conda-forge/osx-arm64::ffmpeg-8.0.0-gpl_h670d5b4_106 \n",
      "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
      "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
      "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
      "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
      "  fontconfig         conda-forge/osx-arm64::fontconfig-2.15.0-h1383a14_1 \n",
      "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
      "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-hc364b38_1 \n",
      "  freetype           conda-forge/osx-arm64::freetype-2.14.1-hce30654_0 \n",
      "  fribidi            conda-forge/osx-arm64::fribidi-1.0.16-hc919400_0 \n",
      "  gdk-pixbuf         conda-forge/osx-arm64::gdk-pixbuf-2.44.4-h7542897_0 \n",
      "  glslang            conda-forge/osx-arm64::glslang-16.0.0-h60b4770_0 \n",
      "  gmp                conda-forge/osx-arm64::gmp-6.3.0-h7bae524_2 \n",
      "  graphite2          conda-forge/osx-arm64::graphite2-1.3.14-hec049ff_2 \n",
      "  harfbuzz           conda-forge/osx-arm64::harfbuzz-12.2.0-haf38c7b_0 \n",
      "  lame               conda-forge/osx-arm64::lame-3.100-h1a8c8d9_1003 \n",
      "  lerc               conda-forge/osx-arm64::lerc-4.0.0-hd64df32_1 \n",
      "  libabseil          conda-forge/osx-arm64::libabseil-20250512.1-cxx17_hd41c47c_0 \n",
      "  libass             conda-forge/osx-arm64::libass-0.17.4-hcbd7ca7_0 \n",
      "  libcxx             conda-forge/osx-arm64::libcxx-21.1.5-hf598326_0 \n",
      "  libdeflate         conda-forge/osx-arm64::libdeflate-1.25-hc11a715_0 \n",
      "  libfreetype        conda-forge/osx-arm64::libfreetype-2.14.1-hce30654_0 \n",
      "  libfreetype6       conda-forge/osx-arm64::libfreetype6-2.14.1-h6da58f4_0 \n",
      "  libglib            conda-forge/osx-arm64::libglib-2.86.1-he69a767_2 \n",
      "  libhwloc           conda-forge/osx-arm64::libhwloc-2.12.1-default_h48b22c3_1002 \n",
      "  libiconv           conda-forge/osx-arm64::libiconv-1.18-h23cfdf5_2 \n",
      "  libintl            conda-forge/osx-arm64::libintl-0.25.1-h493aca8_0 \n",
      "  libjpeg-turbo      conda-forge/osx-arm64::libjpeg-turbo-3.1.2-hc919400_0 \n",
      "  libogg             conda-forge/osx-arm64::libogg-1.3.5-h48c0fde_1 \n",
      "  libopenvino        conda-forge/osx-arm64::libopenvino-2025.2.0-h56e7ac4_1 \n",
      "  libopenvino-arm-c~ conda-forge/osx-arm64::libopenvino-arm-cpu-plugin-2025.2.0-h56e7ac4_1 \n",
      "  libopenvino-auto-~ conda-forge/osx-arm64::libopenvino-auto-batch-plugin-2025.2.0-he81eb65_1 \n",
      "  libopenvino-auto-~ conda-forge/osx-arm64::libopenvino-auto-plugin-2025.2.0-he81eb65_1 \n",
      "  libopenvino-heter~ conda-forge/osx-arm64::libopenvino-hetero-plugin-2025.2.0-h273c05f_1 \n",
      "  libopenvino-ir-fr~ conda-forge/osx-arm64::libopenvino-ir-frontend-2025.2.0-h273c05f_1 \n",
      "  libopenvino-onnx-~ conda-forge/osx-arm64::libopenvino-onnx-frontend-2025.2.0-h6386500_1 \n",
      "  libopenvino-paddl~ conda-forge/osx-arm64::libopenvino-paddle-frontend-2025.2.0-h6386500_1 \n",
      "  libopenvino-pytor~ conda-forge/osx-arm64::libopenvino-pytorch-frontend-2025.2.0-hec049ff_1 \n",
      "  libopenvino-tenso~ conda-forge/osx-arm64::libopenvino-tensorflow-frontend-2025.2.0-hee62d61_1 \n",
      "  libopenvino-tenso~ conda-forge/osx-arm64::libopenvino-tensorflow-lite-frontend-2025.2.0-hec049ff_1 \n",
      "  libopus            conda-forge/osx-arm64::libopus-1.5.2-h48c0fde_0 \n",
      "  libpng             conda-forge/osx-arm64::libpng-1.6.50-h280e0eb_1 \n",
      "  libprotobuf        conda-forge/osx-arm64::libprotobuf-6.31.1-h658db43_2 \n",
      "  librsvg            conda-forge/osx-arm64::librsvg-2.60.0-h5c55ec3_0 \n",
      "  libtiff            conda-forge/osx-arm64::libtiff-4.7.1-h4030677_1 \n",
      "  libusb             conda-forge/osx-arm64::libusb-1.0.29-hbc156a2_0 \n",
      "  libvorbis          conda-forge/osx-arm64::libvorbis-1.3.7-h81086ad_2 \n",
      "  libvpx             conda-forge/osx-arm64::libvpx-1.14.1-h7bae524_0 \n",
      "  libvulkan-loader   conda-forge/osx-arm64::libvulkan-loader-1.4.328.1-h49c215f_0 \n",
      "  libwebp-base       conda-forge/osx-arm64::libwebp-base-1.6.0-h07db88b_0 \n",
      "  libxml2            conda-forge/osx-arm64::libxml2-2.15.1-h9329255_0 \n",
      "  libxml2-16         conda-forge/osx-arm64::libxml2-16-2.15.1-h0ff4647_0 \n",
      "  openh264           conda-forge/osx-arm64::openh264-2.6.0-hb5b2745_0 \n",
      "  pango              conda-forge/osx-arm64::pango-1.56.4-h875632e_0 \n",
      "  pcre2              conda-forge/osx-arm64::pcre2-10.46-h7125dd6_0 \n",
      "  pixman             conda-forge/osx-arm64::pixman-0.46.4-h81086ad_1 \n",
      "  pugixml            conda-forge/osx-arm64::pugixml-1.15-hd3d436d_0 \n",
      "  sdl2               conda-forge/osx-arm64::sdl2-2.32.56-h248ca61_0 \n",
      "  sdl3               conda-forge/osx-arm64::sdl3-3.2.26-h919df07_0 \n",
      "  shaderc            conda-forge/osx-arm64::shaderc-2025.4-h1a5098f_0 \n",
      "  snappy             conda-forge/osx-arm64::snappy-1.2.2-hd121638_0 \n",
      "  spirv-tools        conda-forge/osx-arm64::spirv-tools-2025.4-ha7d2532_0 \n",
      "  svt-av1            conda-forge/osx-arm64::svt-av1-3.1.2-h12ba402_0 \n",
      "  tbb                conda-forge/osx-arm64::tbb-2022.3.0-h66ce52b_1 \n",
      "  x264               conda-forge/osx-arm64::x264-1!164.3095-h57fd34a_2 \n",
      "  x265               conda-forge/osx-arm64::x265-3.5-hbc6ce65_3 \n",
      "  zstd               conda-forge/osx-arm64::zstd-1.5.7-h6491c7d_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | \n",
      "\\ \n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Obtaining file:///Users/lucawilliams/Desktop/Applied%20Machine%20Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting torch==2.5.1 (from t2v_metrics==3.0)\n",
      "  Using cached torch-2.5.1-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.20.1 (from t2v_metrics==3.0)\n",
      "  Using cached torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.5.1 (from t2v_metrics==3.0)\n",
      "  Using cached torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting xformers (from t2v_metrics==3.0)\n",
      "  Using cached xformers-0.0.32.post2.tar.gz (12.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting ftfy>=6.1.1 (from t2v_metrics==3.0)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tqdm>=4.64.1 (from t2v_metrics==3.0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting gdown>=4.7.1 (from t2v_metrics==3.0)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting huggingface-hub>=0.19.4 (from t2v_metrics==3.0)\n",
      "  Using cached huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting matplotlib>=3.6.2 (from t2v_metrics==3.0)\n",
      "  Using cached matplotlib-3.10.7-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy==1.26.4 (from t2v_metrics==3.0)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting open-clip-torch>=2.23.0 (from t2v_metrics==3.0)\n",
      "  Using cached open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting openai (from t2v_metrics==3.0)\n",
      "  Using cached openai-2.7.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting opencv-python>=4.11.0.86 (from t2v_metrics==3.0)\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting opencv-python-headless (from t2v_metrics==3.0)\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pandas>=2.1.4 (from t2v_metrics==3.0)\n",
      "  Using cached pandas-2.3.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting scipy>=1.11.4 (from t2v_metrics==3.0)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting sentencepiece>=0.1.99 (from t2v_metrics==3.0)\n",
      "  Using cached sentencepiece-0.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting transformers==4.49.0 (from t2v_metrics==3.0)\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets>=2.15.0 (from t2v_metrics==3.0)\n",
      "  Using cached datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tokenizers (from t2v_metrics==3.0)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting omegaconf (from t2v_metrics==3.0)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting iopath (from t2v_metrics==3.0)\n",
      "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fairscale (from t2v_metrics==3.0)\n",
      "  Using cached fairscale-0.4.13.tar.gz (266 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scikit-learn (from t2v_metrics==3.0)\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pycocoevalcap (from t2v_metrics==3.0)\n",
      "  Using cached pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting hpsv2 (from t2v_metrics==3.0)\n",
      "  Using cached hpsv2-1.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting clip@ git+https://github.com/openai/CLIP.git (from t2v_metrics==3.0)\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/z0/bghqmr1128z4tjhxrfn3358m0000gn/T/pip-install-s_9odcz5/clip_aa2791b54b1b4ed3905b766ca6c120f2\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting llava@ git+https://github.com/LLaVA-VL/LLaVA-NeXT.git (from t2v_metrics==3.0)\n",
      "  Cloning https://github.com/LLaVA-VL/LLaVA-NeXT.git to /private/var/folders/z0/bghqmr1128z4tjhxrfn3358m0000gn/T/pip-install-s_9odcz5/llava_3fb170dd7b824c4e84396a5906a1ea9f\n",
      "  Resolved https://github.com/LLaVA-VL/LLaVA-NeXT.git to commit e9835311c6f515a13702eb7a7750fcd936f65ed8\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fire==0.4.0 (from t2v_metrics==3.0)\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tiktoken>=0.7.0 (from t2v_metrics==3.0)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting peft==0.5.0 (from t2v_metrics==3.0)\n",
      "  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting matplotlib-inline (from t2v_metrics==3.0)\n",
      "  Downloading matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of t2v-metrics to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/z0/bghqmr1128z4tjhxrfn3358m0000gn/T/pip-install-s_9odcz5/clip_aa2791b54b1b4ed3905b766ca6c120f2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/LLaVA-VL/LLaVA-NeXT.git /private/var/folders/z0/bghqmr1128z4tjhxrfn3358m0000gn/T/pip-install-s_9odcz5/llava_3fb170dd7b824c4e84396a5906a1ea9f\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.16.0 Requires-Python >=3.11; 1.16.0rc1 Requires-Python >=3.11; 1.16.0rc2 Requires-Python >=3.11; 1.16.1 Requires-Python >=3.11; 1.16.2 Requires-Python >=3.11; 1.16.3 Requires-Python >=3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 2.3.0 Requires-Python >=3.11; 2.3.1 Requires-Python >=3.11; 2.3.2 Requires-Python >=3.11; 2.3.3 Requires-Python >=3.11; 2.3.4 Requires-Python >=3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement decord (from t2v-metrics) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for decord\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "ERROR conda.cli.main_run:execute(127): `conda run pip install -e ./t2v_metrics` failed. (See above for error)\n"
     ]
    }
   ],
   "source": [
    "!git submodule update --init --recursive\n",
    "!conda create -n t2v python=3.10 -y\n",
    "%conda install -n t2v pip -y\n",
    "%conda install -n t2v ffmpeg -c conda-forge -y\n",
    "!conda run -n t2v pip install -e ./t2v_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc072f6",
   "metadata": {},
   "source": [
    "### VQA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8186f567",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mt2v_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m t2v_metrics\n\u001b[1;32m      2\u001b[0m clip_flant5_score \u001b[38;5;241m=\u001b[39m t2v_metrics\u001b[38;5;241m.\u001b[39mVQAScore(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip-flant5-xxl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# our recommended scoring model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m### For a single (image, text) pair\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Applied Machine Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics/t2v_metrics/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/clipscore_models/InternVideo2/multi_modality/\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_CACHE_DIR\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvqascore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VQAScore, list_all_vqascore_models\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipscore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CLIPScore, list_all_clipscore_models\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mitmscore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ITMScore, list_all_itmscore_models\n",
      "File \u001b[0;32m~/Desktop/Applied Machine Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics/t2v_metrics/vqascore.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Score\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_CACHE_DIR\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvqascore_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_all_vqascore_models, get_vqascore_model\n",
      "File \u001b[0;32m~/Desktop/Applied Machine Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics/t2v_metrics/score.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_CACHE_DIR\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvqascore_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmm_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mImageTextDict\u001b[39;00m(TypedDict):\n\u001b[1;32m     15\u001b[0m     images: List[\u001b[38;5;28mstr\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Applied Machine Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics/t2v_metrics/models/vqascore_models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclip_t5_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CLIP_T5_MODELS, CLIPT5Model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllava_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLAVA_MODELS, LLaVAModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllava16_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLAVA16_MODELS, LLaVA16Model\n",
      "File \u001b[0;32m~/Desktop/Applied Machine Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics/t2v_metrics/models/vqascore_models/clip_t5_model.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvqa_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VQAScoreModel\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmm_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expand2square, load_pretrained_model, t5_tokenizer_image_token\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_CACHE_DIR, CONTEXT_LEN, SYSTEM_MSG, DEFAULT_IMAGE_TOKEN, IGNORE_INDEX\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclip_t5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CLIPT5ForConditionalGeneration, ModelArguments\n",
      "File \u001b[0;32m~/Desktop/Applied Machine Learning/Attributes-Effect-on-OOD-Performance/t2v_metrics/t2v_metrics/models/vqascore_models/mm_utils.py:11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_CACHE_DIR, IMAGE_TOKEN_INDEX\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# from moviepy.editor import VideoFileClip\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ceil, sqrt\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from t2v_metrics import t2v_metrics\n",
    "clip_flant5_score = t2v_metrics.VQAScore(model='clip-flant5-xxl') # our recommended scoring model\n",
    "\n",
    "### For a single (image, text) pair\n",
    "image = \"images/0.png\" # an image path in string format\n",
    "text = \"someone talks on the phone angrily while another person sits happily\"\n",
    "score = clip_flant5_score(images=[image], texts=[text])\n",
    "\n",
    "### Alternatively, if you want to calculate the pairwise similarity scores \n",
    "### between M images and N texts, run the following to return a M x N score tensor.\n",
    "images = [\"images/0.png\", \"images/1.png\"]\n",
    "texts = [\"someone talks on the phone angrily while another person sits happily\",\n",
    "         \"someone talks on the phone happily while another person sits angrily\"]\n",
    "scores = clip_flant5_score(images=images, texts=texts) # scores[i][j] is the score between image i and text j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
